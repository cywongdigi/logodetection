Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount("/drive", force_remount=True).
/drive/My Drive/Colab Notebooks
[INFO] Running on Google Colab
[INFO] model_type: lbp
[INFO] Preprocessing images...
[INFO] Loading images and extracting features...
[INFO] Splitting data into training and testing sets...
[INFO] Split into 1280 training and 320 testing samples.
[INFO] Preprocessed data for model type lbp.
[INFO] Built lbp model.
[INFO] Training model...
  epoch    train_loss    train_acc    valid_loss    valid_acc     dur
-------  ------------  -----------  ------------  -----------  ------
      1        3.0483       0.0523        3.0475       0.0531  0.1941
      2        3.0477       0.0523        3.0474       0.0531  0.0413
      3        3.0476       0.0523        3.0473       0.0531  0.0399
      4        3.0475       0.0523        3.0471       0.0531  0.0394
      5        3.0474       0.0523        3.0470       0.0531  0.0394
      6        3.0472       0.0523        3.0469       0.0531  0.0396
      7        3.0471       0.0523        3.0468       0.0531  0.0393
      8        3.0470       0.0523        3.0466       0.0531  0.0398
      9        3.0469       0.0523        3.0466       0.0531  0.0398
     10        3.0469       0.0523        3.0466       0.0531  0.0393
     11        3.0469       0.0523        3.0466       0.0531  0.0399
     12        3.0469       0.0523        3.0466       0.0531  0.0391
     13        3.0469       0.0523        3.0466       0.0531  0.0397
     14        3.0469       0.0523        3.0466       0.0531  0.0393
     15        3.0469       0.0523        3.0466       0.0531  0.0396
     16        3.0468       0.0523        3.0466       0.0531  0.0395
     17        3.0468       0.0523        3.0466       0.0531  0.0394
     18        3.0468       0.0523        3.0466       0.0531  0.0392
     19        3.0468       0.0523        3.0466       0.0531  0.0397
     20        3.0468       0.0523        3.0466       0.0531  0.0398
     21        3.0468       0.0523        3.0466       0.0531  0.0394
     22        3.0468       0.0523        3.0466       0.0531  0.0399
     23        3.0468       0.0523        3.0466       0.0531  0.0397
     24        3.0468       0.0523        3.0466       0.0531  0.0396
     25        3.0468       0.0523        3.0466       0.0531  0.0411
     26        3.0468       0.0523        3.0466       0.0531  0.0395
     27        3.0468       0.0523        3.0466       0.0531  0.0411
     28        3.0468       0.0523        3.0466       0.0531  0.0399
     29        3.0468       0.0523        3.0466       0.0531  0.0394
     30        3.0468       0.0523        3.0466       0.0531  0.0400
     31        3.0468       0.0523        3.0466       0.0531  0.0404
     32        3.0468       0.0523        3.0466       0.0531  0.0396
     33        3.0468       0.0523        3.0466       0.0531  0.0400
     34        3.0468       0.0523        3.0466       0.0531  0.0393
     35        3.0468       0.0523        3.0466       0.0531  0.0397
     36        3.0468       0.0523        3.0466       0.0531  0.0396
     37        3.0468       0.0523        3.0466       0.0531  0.0399
     38        3.0468       0.0523        3.0466       0.0531  0.0399
     39        3.0468       0.0523        3.0466       0.0531  0.0395
     40        3.0468       0.0523        3.0466       0.0531  0.0394
     41        3.0468       0.0523        3.0466       0.0531  0.0393
     42        3.0468       0.0523        3.0466       0.0531  0.0397
     43        3.0468       0.0523        3.0466       0.0531  0.0392
     44        3.0468       0.0523        3.0466       0.0531  0.0391
     45        3.0468       0.0523        3.0466       0.0531  0.0392
     46        3.0468       0.0523        3.0466       0.0531  0.0396
     47        3.0468       0.0523        3.0466       0.0531  0.0405
     48        3.0468       0.0523        3.0466       0.0531  0.0396
     49        3.0468       0.0523        3.0466       0.0531  0.0391
     50        3.0468       0.0523        3.0466       0.0531  0.0390
     51        3.0468       0.0523        3.0466       0.0531  0.0393
     52        3.0468       0.0523        3.0466       0.0531  0.0401
     53        3.0468       0.0523        3.0466       0.0531  0.0397
     54        3.0468       0.0523        3.0466       0.0531  0.0390
     55        3.0468       0.0523        3.0466       0.0531  0.0390
     56        3.0468       0.0523        3.0466       0.0531  0.0397
     57        3.0468       0.0523        3.0466       0.0531  0.0393
     58        3.0468       0.0523        3.0466       0.0531  0.0397
     59        3.0468       0.0523        3.0466       0.0531  0.0392
     60        3.0468       0.0523        3.0466       0.0531  0.0389
     61        3.0468       0.0523        3.0466       0.0531  0.0389
     62        3.0468       0.0523        3.0466       0.0531  0.0390
     63        3.0468       0.0523        3.0466       0.0531  0.0389
     64        3.0468       0.0523        3.0466       0.0531  0.0390
     65        3.0468       0.0523        3.0466       0.0531  0.0393
     66        3.0468       0.0523        3.0466       0.0531  0.0396
     67        3.0468       0.0523        3.0466       0.0531  0.0407
     68        3.0468       0.0523        3.0466       0.0531  0.0392
     69        3.0468       0.0523        3.0466       0.0531  0.0394
     70        3.0468       0.0523        3.0466       0.0531  0.0393
     71        3.0468       0.0523        3.0466       0.0531  0.0392
     72        3.0468       0.0523        3.0466       0.0531  0.0392
     73        3.0468       0.0523        3.0466       0.0531  0.0395
     74        3.0468       0.0523        3.0466       0.0531  0.0392
     75        3.0468       0.0523        3.0466       0.0531  0.0410
     76        3.0468       0.0523        3.0466       0.0531  0.0392
     77        3.0468       0.0523        3.0466       0.0531  0.0393
     78        3.0468       0.0523        3.0466       0.0531  0.0400
     79        3.0468       0.0523        3.0466       0.0531  0.0397
     80        3.0468       0.0523        3.0466       0.0531  0.0391
     81        3.0468       0.0523        3.0466       0.0531  0.0389
     82        3.0468       0.0523        3.0466       0.0531  0.0390
     83        3.0468       0.0523        3.0466       0.0531  0.0390
     84        3.0468       0.0523        3.0466       0.0531  0.0389
     85        3.0468       0.0523        3.0466       0.0531  0.0390
     86        3.0468       0.0523        3.0466       0.0531  0.0390
     87        3.0468       0.0523        3.0466       0.0531  0.0393
     88        3.0468       0.0523        3.0466       0.0531  0.0390
     89        3.0468       0.0523        3.0466       0.0531  0.0392
     90        3.0468       0.0523        3.0466       0.0531  0.0390
     91        3.0468       0.0523        3.0466       0.0531  0.0390
     92        3.0468       0.0523        3.0466       0.0531  0.0389
     93        3.0468       0.0523        3.0466       0.0531  0.0390
     94        3.0468       0.0523        3.0466       0.0531  0.0389
     95        3.0468       0.0523        3.0466       0.0531  0.0393
     96        3.0468       0.0523        3.0466       0.0531  0.0423
     97        3.0468       0.0523        3.0466       0.0531  0.0420
     98        3.0468       0.0523        3.0466       0.0531  0.0394
     99        3.0468       0.0523        3.0466       0.0531  0.0392
    100        3.0468       0.0523        3.0466       0.0531  0.0393
[INFO] Evaluating model...
Accuracy: 0.0531
Precision: 0.0045
Recall: 0.0531
F1 Score: 0.0074
Specificity: 0.9019
Confusion Matrix:
[[ 0  0  0  0  0  0  0  0  0  0  0  3  0  0 13  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  4  0  0 12  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0 15  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  4  0  0 12  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  3  0  0 13  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  6  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0 15  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0 15  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0 15  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0 15  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0 14  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0 15  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0 15  0  0  0  0  0]]
[INFO] Total run time: 73.25 seconds
[INFO] Saving model, scaler, and label dictionary...
[INFO] Saved lbp model, scaler, and label dictionary.
[INFO] Loading model and label dictionary for lbp...
[INFO] Preprocessing test images...
[INFO] Loading test images and extracting features...
[INFO] Evaluating model on test data...
Accuracy: 0.0393
Precision: 0.0062
Recall: 0.0393
F1 Score: 0.0069
Specificity: 0.3475
Confusion Matrix:
[[ 0  0  0  0  0  0  0  0  0  0  0  2  0  0 26  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  9  0  0 26  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0 26  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0 19  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  5  0  0 21  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0 21  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  4  0  0 21  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  5  0  0 25  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  5  0  0 27  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0 62  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0 29  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 34  0  1  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0 21  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0 23  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0 27  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0 28  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 30  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0 23  0  0  0  0  0]]
[INFO] Total run time: 99.32 seconds
